{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c319a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e5e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd3d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb80b9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bdee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fdb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = r'H:\\sprints\\face recognition task\\105_classes_pins_dataset' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0519ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Specify the path to the main directory\n",
    "main_directory = r'H:\\sprints\\face recognition task\\105_classes_pins_dataset' \n",
    "\n",
    "# Check if the main directory exists\n",
    "if not os.path.exists(main_directory):\n",
    "    print(\"The specified main directory does not exist.\")\n",
    "else:\n",
    "    print(\"Main directory exists, proceeding...\")\n",
    "\n",
    "# Initialize counts\n",
    "folder_count = 0\n",
    "total_file_count = 0\n",
    "\n",
    "# Iterate through the main directory\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Count folders\n",
    "    folder_count += len(dirs)\n",
    "    \n",
    "    # Count files in each folder\n",
    "    folder_file_count = len(files)\n",
    "    total_file_count += folder_file_count\n",
    "    \n",
    "    # Print the folder name and the number of files in that folder\n",
    "    print(f\"Folder: {os.path.basename(root)}, Files: {folder_file_count}\")\n",
    "    \n",
    "\n",
    "# Print the overall results\n",
    "print(f\"\\nNumber of folders: {folder_count}\")\n",
    "print(f\"Total number of files: {total_file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f872df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths\n",
    "main_directory = r'H:\\\\sprints\\\\face recognition task\\\\105_classes_pins_dataset'  \n",
    "output_folder = r'H:\\\\sprints\\\\face recognition task\\\\cropped_faces'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d36be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Specify the paths\n",
    "main_directory = r'H:\\\\sprints\\\\face recognition task\\\\105_classes_pins_dataset'  \n",
    "output_folder = r'H:\\\\sprints\\\\face recognition task\\\\cropped_faces'  \n",
    "\n",
    "# Target size for output images\n",
    "target_size = (128, 128)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Load Haar Cascade Classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Iterate through each class folder\n",
    "for class_folder in os.listdir(main_directory):\n",
    "    class_path = os.path.join(main_directory, class_folder)\n",
    "\n",
    "    if os.path.isdir(class_path):  # Ensure it is a directory\n",
    "        # Create a specific output subfolder for each class\n",
    "        class_output_folder = os.path.join(output_folder, class_folder)\n",
    "        if not os.path.exists(class_output_folder):\n",
    "            os.makedirs(class_output_folder)  # Create subfolder for class if it doesn't exist\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                # Read the image\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                if img is None:  # Skip if image is not readable\n",
    "                    print(f\"Failed to read image: {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Convert the image to grayscale for detection\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detect faces\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "                # Crop and save each detected face\n",
    "                for i, (x, y, w, h) in enumerate(faces):\n",
    "                    face = img[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Resize the cropped face to the target size\n",
    "                    resized_face = cv2.resize(face, target_size)\n",
    "                    \n",
    "                    # Generate a unique filename\n",
    "                    face_filename = f\"{img_name.split('.')[0]}_face_{i}.jpg\"\n",
    "                    face_path = os.path.join(class_output_folder, face_filename)\n",
    "                    \n",
    "                    # Save the resized cropped face\n",
    "                    cv2.imwrite(face_path, resized_face)\n",
    "\n",
    "                print(f\"Processed image: {img_name} in class '{class_folder}', Found {len(faces)} faces.\")\n",
    "\n",
    "print(\"Face detection, cropping, and resizing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c55c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "dataset = []\n",
    "count=0\n",
    "for file in os.listdir(output_folder):\n",
    "    path=os.path.join(output_folder,file)\n",
    "    t=0\n",
    "    for img in os.listdir(path):\n",
    "        image=load_img(os.path.join(path,img),grayscale=False,color_mode='rgb',target_size=(128,128))\n",
    "        image = np.array(image)/255.0\n",
    "        t+=1\n",
    "        dataset.append([image,count])\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fa82978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical \n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for image, label in dataset:\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "labels_1 = to_categorical(labels)\n",
    "data=np.array(data)\n",
    "labels1=np.array(labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb19248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)\n",
    "# print(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b77c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test,y_train,y_test = train_test_split(data,labels1,test_size=0.2,random_state=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8de362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "# Load VGG16 model with pre-trained weights, excluding the top (fully connected layers)\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "# # Freeze all layers in the base VGG16 model\n",
    "# base_model.trainable = False\n",
    "# for layer in base_model.layers[-1:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# Load the VGG model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Freeze the layers of the VGG model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "# import os\n",
    "\n",
    "# weights_path = r'H:\\sprints\\face recognition task\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# if os.path.exists(weights_path):\n",
    "#     from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "#     # Load ResNet50 model with custom weights, excluding the fully connected layers (include_top=False)\n",
    "#     base_model = ResNet50(weights=weights_path, include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#     # Freeze the layers of the ResNet model\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "#     base_model.summary()\n",
    "# else:\n",
    "#     print(f\"Weights file not found at: {weights_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c4f6bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f29ebe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "\n",
    "# Create a new model with additional modifications\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu', kernel_regularizer=l2(0.0001)),  \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2), \n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(105, activation='softmax') \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0288a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87788965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1026/1026 [==============================] - 26s 20ms/step - loss: 4.4006 - accuracy: 0.0763 - val_loss: 3.6049 - val_accuracy: 0.1764\n",
      "Epoch 2/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 3.7148 - accuracy: 0.1729 - val_loss: 3.4511 - val_accuracy: 0.2277\n",
      "Epoch 3/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 3.4238 - accuracy: 0.2520 - val_loss: 3.3726 - val_accuracy: 0.2793\n",
      "Epoch 4/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 3.2173 - accuracy: 0.3118 - val_loss: 3.2608 - val_accuracy: 0.3105\n",
      "Epoch 5/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 3.0566 - accuracy: 0.3551 - val_loss: 3.1912 - val_accuracy: 0.3501\n",
      "Epoch 6/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.9402 - accuracy: 0.3948 - val_loss: 3.0710 - val_accuracy: 0.3771\n",
      "Epoch 7/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.8359 - accuracy: 0.4215 - val_loss: 3.1310 - val_accuracy: 0.3790\n",
      "Epoch 8/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.7200 - accuracy: 0.4560 - val_loss: 3.1284 - val_accuracy: 0.3927\n",
      "Epoch 9/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.6188 - accuracy: 0.4812 - val_loss: 3.0953 - val_accuracy: 0.4102\n",
      "Epoch 10/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.5284 - accuracy: 0.4984 - val_loss: 3.1465 - val_accuracy: 0.4031\n",
      "Epoch 11/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.4661 - accuracy: 0.5240 - val_loss: 2.9283 - val_accuracy: 0.4498\n",
      "Epoch 12/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.4148 - accuracy: 0.5412 - val_loss: 3.1019 - val_accuracy: 0.4203\n",
      "Epoch 13/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.3292 - accuracy: 0.5615 - val_loss: 3.2215 - val_accuracy: 0.3917\n",
      "Epoch 14/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.2794 - accuracy: 0.5723 - val_loss: 3.0330 - val_accuracy: 0.4482\n",
      "Epoch 15/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 2.2341 - accuracy: 0.5850 - val_loss: 3.0032 - val_accuracy: 0.4657\n",
      "Epoch 16/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 2.1615 - accuracy: 0.6102 - val_loss: 3.1681 - val_accuracy: 0.4381\n",
      "Epoch 17/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.1731 - accuracy: 0.5984 - val_loss: 2.9940 - val_accuracy: 0.4674\n",
      "Epoch 18/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 2.0889 - accuracy: 0.6247 - val_loss: 3.1123 - val_accuracy: 0.4612\n",
      "Epoch 19/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 2.0923 - accuracy: 0.6241 - val_loss: 3.1889 - val_accuracy: 0.4560\n",
      "Epoch 20/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 2.0469 - accuracy: 0.6373 - val_loss: 3.2115 - val_accuracy: 0.4427\n",
      "Epoch 21/70\n",
      "1026/1026 [==============================] - 19s 19ms/step - loss: 1.9999 - accuracy: 0.6488 - val_loss: 3.5682 - val_accuracy: 0.3992\n",
      "Epoch 22/70\n",
      "1026/1026 [==============================] - 20s 19ms/step - loss: 1.9553 - accuracy: 0.6613 - val_loss: 3.0931 - val_accuracy: 0.4625\n"
     ]
    }
   ],
   "source": [
    "# Set up callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=70,\n",
    "    batch_size=12,\n",
    "    validation_data=(x_test,y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feac1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5341298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12312, 128, 128, 3) (12312, 105)\n",
      "(3079, 128, 128, 3) (3079, 105)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c5686de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "weights = 'H:\\sprints\\inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5' \n",
    "model_in = InceptionV3(input_shape =(128,128,3),include_top=False,weights=None)\n",
    "model_in.load_weights(weights)\n",
    "for layer in model_in.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e9f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 63, 63, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 63, 63, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 63, 63, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 61, 61, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 61, 61, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 61, 61, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 61, 61, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 61, 61, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 61, 61, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 30, 30, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 30, 30, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 30, 30, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 30, 30, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 28, 28, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 28, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 28, 28, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 13, 13, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 13, 13, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 13, 13, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 13, 13, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 13, 13, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 13, 13, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 13, 13, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 13, 13, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 13, 13, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 13, 13, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 13, 13, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 13, 13, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 13, 13, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 13, 13, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 13, 13, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 13, 13, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 13, 13, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 13, 13, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 13, 13, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 13, 13, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 13, 13, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 13, 13, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 13, 13, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 13, 13, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 13, 13, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 13, 13, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 13, 13, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 13, 13, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 13, 13, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 13, 13, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 13, 13, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 13, 13, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 13, 13, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 13, 13, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 13, 13, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 13, 13, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 13, 13, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 13, 13, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 13, 13, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 13, 13, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 13, 13, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 13, 13, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 13, 13, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 13, 13, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 13, 13, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 13, 13, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 13, 13, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 13, 13, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 13, 13, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 13, 13, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 13, 13, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 13, 13, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 13, 13, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 13, 13, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 13, 13, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 13, 13, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 13, 13, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 13, 13, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 13, 13, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 13, 13, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 13, 13, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 6, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 6, 6, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 6, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 6, 6, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 6, 6, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 6, 6, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 6, 6, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 6, 6, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 6, 6, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 6, 6, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 6, 6, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 6, 6, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 6, 6, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 6, 6, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 6, 6, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 6, 6, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 6, 6, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 6, 6, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 6, 6, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 6, 6, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 6, 6, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 6, 6, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 6, 6, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 6, 6, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 6, 6, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 6, 6, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 6, 6, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 6, 6, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 6, 6, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 6, 6, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 6, 6, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 6, 6, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 6, 6, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 6, 6, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 6, 6, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 6, 6, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 6, 6, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 6, 6, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 6, 6, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 6, 6, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 6, 6, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 6, 6, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 6, 6, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 6, 6, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 6, 6, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 6, 6, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 6, 6, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 6, 6, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 6, 6, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 6, 6, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 6, 6, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 6, 6, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 6, 6, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 6, 6, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 6, 6, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 6, 6, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 6, 6, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 6, 6, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 6, 6, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 6, 6, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 6, 6, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 6, 6, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 6, 6, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 6, 6, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 6, 6, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 6, 6, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 6, 6, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 6, 6, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 6, 6, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 6, 6, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 6, 6, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 6, 6, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 6, 6, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 6, 6, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 6, 6, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 6, 6, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 6, 6, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 6, 6, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 6, 6, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 6, 6, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 6, 6, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 6, 6, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 6, 6, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 2, 2, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 2, 2, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 2, 2, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 2, 2, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 2, 2, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 2, 2, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 2, 2, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 2, 2, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 2, 2, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 2, 2, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 2, 2, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 2, 2, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 2, 2, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 2, 2, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 2, 2, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 2, 2, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 2, 2, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 2, 2, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2, 2, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 2, 2, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 2, 2, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 2, 2, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 2, 2, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 2, 2, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 2, 2, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 2, 2, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 2, 2, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 2, 2, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 2, 2, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 2, 2, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 2, 2, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 2, 2, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 2, 2, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 2, 2, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 2, 2, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2, 2, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 2, 2, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_in.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42fb2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "# history = Sequential([\n",
    "#     model_in,\n",
    "#     Flatten(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b578df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape: (None, 6, 6, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = model_in.get_layer('mixed5')\n",
    "print('last layer output shape:', last_layer.output_shape)\n",
    "last_output = last_layer.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c55cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 27648)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de21c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(1024, activation='leaky_relu', activity_regularizer=l2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12d40911",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(512, activation='leaky_relu', activity_regularizer=l2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c1b49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final output layer\n",
    "x = layers.Dense(105, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1d32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model=Model(model_in.input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f356a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.compile(optimizer=RMSprop(learning_rate=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef165791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "batch_size=32\n",
    "epochs=100\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',patience=5,restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c14ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "385/385 [==============================] - 12s 22ms/step - loss: 5.5980 - accuracy: 0.0292 - val_loss: 3.8551 - val_accuracy: 0.1650\n",
      "Epoch 2/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 4.4453 - accuracy: 0.1052 - val_loss: 3.1946 - val_accuracy: 0.3144\n",
      "Epoch 3/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 3.7634 - accuracy: 0.1898 - val_loss: 2.7708 - val_accuracy: 0.4167\n",
      "Epoch 4/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 3.2118 - accuracy: 0.2783 - val_loss: 2.4663 - val_accuracy: 0.4826\n",
      "Epoch 5/100\n",
      "385/385 [==============================] - 7s 17ms/step - loss: 2.8115 - accuracy: 0.3560 - val_loss: 2.2227 - val_accuracy: 0.5450\n",
      "Epoch 6/100\n",
      "385/385 [==============================] - 7s 17ms/step - loss: 2.4860 - accuracy: 0.4225 - val_loss: 2.0339 - val_accuracy: 0.5836\n",
      "Epoch 7/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 2.2189 - accuracy: 0.4802 - val_loss: 1.8982 - val_accuracy: 0.6187\n",
      "Epoch 8/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 1.9485 - accuracy: 0.5461 - val_loss: 1.7507 - val_accuracy: 0.6450\n",
      "Epoch 9/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 1.7475 - accuracy: 0.5941 - val_loss: 1.6439 - val_accuracy: 0.6736\n",
      "Epoch 10/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 1.5726 - accuracy: 0.6375 - val_loss: 1.5470 - val_accuracy: 0.6954\n",
      "Epoch 11/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 1.4072 - accuracy: 0.6812 - val_loss: 1.4737 - val_accuracy: 0.7057\n",
      "Epoch 12/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 1.2827 - accuracy: 0.7141 - val_loss: 1.4106 - val_accuracy: 0.7233\n",
      "Epoch 13/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 1.1460 - accuracy: 0.7551 - val_loss: 1.3435 - val_accuracy: 0.7418\n",
      "Epoch 14/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 1.0470 - accuracy: 0.7787 - val_loss: 1.2898 - val_accuracy: 0.7476\n",
      "Epoch 15/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.9665 - accuracy: 0.7995 - val_loss: 1.2556 - val_accuracy: 0.7584\n",
      "Epoch 16/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.8629 - accuracy: 0.8289 - val_loss: 1.2045 - val_accuracy: 0.7541\n",
      "Epoch 17/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.7876 - accuracy: 0.8498 - val_loss: 1.1583 - val_accuracy: 0.7710\n",
      "Epoch 18/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.7247 - accuracy: 0.8699 - val_loss: 1.1332 - val_accuracy: 0.7704\n",
      "Epoch 19/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.6675 - accuracy: 0.8830 - val_loss: 1.0816 - val_accuracy: 0.7889\n",
      "Epoch 20/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.5931 - accuracy: 0.9051 - val_loss: 1.0616 - val_accuracy: 0.7902\n",
      "Epoch 21/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.5589 - accuracy: 0.9156 - val_loss: 1.0421 - val_accuracy: 0.7905\n",
      "Epoch 22/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.5085 - accuracy: 0.9256 - val_loss: 1.0214 - val_accuracy: 0.7999\n",
      "Epoch 23/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.4648 - accuracy: 0.9395 - val_loss: 1.0104 - val_accuracy: 0.8022\n",
      "Epoch 24/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.4420 - accuracy: 0.9406 - val_loss: 0.9888 - val_accuracy: 0.8016\n",
      "Epoch 25/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.4094 - accuracy: 0.9483 - val_loss: 0.9753 - val_accuracy: 0.8019\n",
      "Epoch 26/100\n",
      "385/385 [==============================] - 7s 18ms/step - loss: 0.3762 - accuracy: 0.9586 - val_loss: 0.9494 - val_accuracy: 0.8068\n",
      "Epoch 27/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.3496 - accuracy: 0.9653 - val_loss: 0.9341 - val_accuracy: 0.8107\n",
      "Epoch 28/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.3309 - accuracy: 0.9675 - val_loss: 0.9302 - val_accuracy: 0.8113\n",
      "Epoch 29/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.3123 - accuracy: 0.9717 - val_loss: 0.9057 - val_accuracy: 0.8158\n",
      "Epoch 30/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.2894 - accuracy: 0.9767 - val_loss: 0.8859 - val_accuracy: 0.8142\n",
      "Epoch 31/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.2821 - accuracy: 0.9769 - val_loss: 0.8799 - val_accuracy: 0.8194\n",
      "Epoch 32/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.2610 - accuracy: 0.9821 - val_loss: 0.8771 - val_accuracy: 0.8201\n",
      "Epoch 33/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.2535 - accuracy: 0.9812 - val_loss: 0.8602 - val_accuracy: 0.8253\n",
      "Epoch 34/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.2388 - accuracy: 0.9853 - val_loss: 0.8521 - val_accuracy: 0.8256\n",
      "Epoch 35/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.2279 - accuracy: 0.9866 - val_loss: 0.8472 - val_accuracy: 0.8256\n",
      "Epoch 36/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.2168 - accuracy: 0.9890 - val_loss: 0.8468 - val_accuracy: 0.8256\n",
      "Epoch 37/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.2117 - accuracy: 0.9894 - val_loss: 0.8395 - val_accuracy: 0.8266\n",
      "Epoch 38/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.2029 - accuracy: 0.9910 - val_loss: 0.8328 - val_accuracy: 0.8292\n",
      "Epoch 39/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1967 - accuracy: 0.9906 - val_loss: 0.8091 - val_accuracy: 0.8366\n",
      "Epoch 40/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1845 - accuracy: 0.9933 - val_loss: 0.8152 - val_accuracy: 0.8275\n",
      "Epoch 41/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1829 - accuracy: 0.9923 - val_loss: 0.8126 - val_accuracy: 0.8311\n",
      "Epoch 42/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1746 - accuracy: 0.9932 - val_loss: 0.7946 - val_accuracy: 0.8350\n",
      "Epoch 43/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1716 - accuracy: 0.9955 - val_loss: 0.7929 - val_accuracy: 0.8383\n",
      "Epoch 44/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1695 - accuracy: 0.9938 - val_loss: 0.7854 - val_accuracy: 0.8386\n",
      "Epoch 45/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1620 - accuracy: 0.9946 - val_loss: 0.7905 - val_accuracy: 0.8366\n",
      "Epoch 46/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1590 - accuracy: 0.9949 - val_loss: 0.7812 - val_accuracy: 0.8366\n",
      "Epoch 47/100\n",
      "385/385 [==============================] - 8s 21ms/step - loss: 0.1552 - accuracy: 0.9963 - val_loss: 0.7793 - val_accuracy: 0.8389\n",
      "Epoch 48/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1535 - accuracy: 0.9950 - val_loss: 0.7834 - val_accuracy: 0.8389\n",
      "Epoch 49/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1504 - accuracy: 0.9962 - val_loss: 0.7799 - val_accuracy: 0.8405\n",
      "Epoch 50/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1468 - accuracy: 0.9963 - val_loss: 0.7624 - val_accuracy: 0.8402\n",
      "Epoch 51/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1442 - accuracy: 0.9957 - val_loss: 0.7749 - val_accuracy: 0.8409\n",
      "Epoch 52/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1418 - accuracy: 0.9968 - val_loss: 0.7780 - val_accuracy: 0.8370\n",
      "Epoch 53/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1349 - accuracy: 0.9981 - val_loss: 0.7606 - val_accuracy: 0.8425\n",
      "Epoch 54/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1324 - accuracy: 0.9972 - val_loss: 0.7750 - val_accuracy: 0.8353\n",
      "Epoch 55/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1302 - accuracy: 0.9974 - val_loss: 0.7551 - val_accuracy: 0.8431\n",
      "Epoch 56/100\n",
      "385/385 [==============================] - 7s 19ms/step - loss: 0.1281 - accuracy: 0.9976 - val_loss: 0.7606 - val_accuracy: 0.8438\n",
      "Epoch 57/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1282 - accuracy: 0.9973 - val_loss: 0.7421 - val_accuracy: 0.8496\n",
      "Epoch 58/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1265 - accuracy: 0.9978 - val_loss: 0.7521 - val_accuracy: 0.8444\n",
      "Epoch 59/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1221 - accuracy: 0.9976 - val_loss: 0.7394 - val_accuracy: 0.8451\n",
      "Epoch 60/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1228 - accuracy: 0.9981 - val_loss: 0.7383 - val_accuracy: 0.8461\n",
      "Epoch 61/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1201 - accuracy: 0.9981 - val_loss: 0.7394 - val_accuracy: 0.8425\n",
      "Epoch 62/100\n",
      "385/385 [==============================] - 8s 20ms/step - loss: 0.1156 - accuracy: 0.9985 - val_loss: 0.7411 - val_accuracy: 0.8480\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=batch_size,epochs=100,validation_data=[x_test,y_test],callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7c4c0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 1s 14ms/step - loss: 0.7421 - accuracy: 0.8496\n"
     ]
    }
   ],
   "source": [
    "loss , accuracy = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c8c9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the simplified data augmentation transformations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values\n",
    "    rotation_range=3,  # Random rotation between 0 and 10 degrees\n",
    ")\n",
    "\n",
    "# Validation data only requires rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Apply the simplified data augmentation to the training data\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
    "\n",
    "# Apply rescaling to the validation data\n",
    "validation_generator = test_datagen.flow(x_test, y_test, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92fc5c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "385/385 [==============================] - 22s 56ms/step - loss: 2.9275 - accuracy: 0.3242 - val_loss: 20.9588 - val_accuracy: 0.0451\n",
      "Epoch 2/70\n",
      "385/385 [==============================] - 23s 59ms/step - loss: 2.8639 - accuracy: 0.3338 - val_loss: 22.4688 - val_accuracy: 0.0169\n",
      "Epoch 3/70\n",
      "385/385 [==============================] - 20s 53ms/step - loss: 2.7910 - accuracy: 0.3492 - val_loss: 24.3655 - val_accuracy: 0.0188\n",
      "Epoch 4/70\n",
      "385/385 [==============================] - 21s 54ms/step - loss: 2.7433 - accuracy: 0.3581 - val_loss: 26.6010 - val_accuracy: 0.0240\n",
      "Epoch 5/70\n",
      "385/385 [==============================] - 21s 54ms/step - loss: 2.6827 - accuracy: 0.3648 - val_loss: 26.9618 - val_accuracy: 0.0114\n",
      "Epoch 6/70\n",
      "385/385 [==============================] - 21s 54ms/step - loss: 2.6637 - accuracy: 0.3713 - val_loss: 31.4449 - val_accuracy: 0.0192\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,batch_size=batch_size,epochs=70,validation_data=validation_generator,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f52ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49efe71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkernel",
   "language": "python",
   "name": "dkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
